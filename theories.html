<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="utf-8"> <meta
name="viewport" content="width=device-width, initial-scale=1,
shrink-to-fit=no"> <title>How Your Brain Believes Without Thinking - Four Psychology Theories - SocialCybersecurity.org</title> <link rel="stylesheet"
href="css/style.css"> <link rel="stylesheet" type="text/css"
href="//fonts.googleapis.com/css?family=Open+Sans" /> <link
rel="shortcut icon" href="images/favicon.ico" type="image/x-icon" />
</head>

<body>

<!-- Main Content --> <main> <header> <div style="text-align: left">
<img src='images/favicon.png' style='float: left; max-height: 1.25em;
margin: 0px 5px 0px 0px'/> </div><a href="index.html"
style="text-transform: uppercase; text-decoration:
none">SocialCybersecurity.org</a> </header>

<div class="flex-container wrapper">

    <!-- Content --> <section class="content"> <h1>Why We Fall for
    Misleading or False Information</h1>  <iframe width="560"
    height="315" src="https://www.youtube.com/embed/WF-ltGozp1k"
    frameborder="0" allow="accelerometer; autoplay; encrypted-media;
    gyroscope; picture-in-picture" allowfullscreen></iframe></p>

    <span> In our research into the human factors of cybersecurity, we
    look at theories from psychology of how your brain believes things
    without really thinking about them &mdash; what scientists know
    about how we “catch” false ideas before we even realize it.</p>

The first idea is that <a
href="https://www.spring.org.uk/2009/09/why-you-cant-help-believing-
everything-you-read.php">you can't help believing everything that you
read.</a> Our minds accept all things that we encounter at face value
&mdash; at least, until we have the time to weigh it and judge whether
what we perceive is trustworthy.</p>

The second idea is that we use two different systems of thinking &mdash;
<a href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow">one
fast, and one slow.</a> System 1 is unconscious, nonrational and
instantaneous, while System 2 is the one that is deliberate, rational,
and takes time. System 1 is the one that we likely use the most.</p>

The third idea is that marketers and salespeople, along with
cyberattackers and con artists, <a
href="https://en.wikipedia.org/wiki/Influence:_Science_and_Practice">use
social “weapons” to influence our behavior.</a> These include Liking,
Authority, and Social Proof. We want people to show their approval to us
and to think positively of us. Other weapons include Scarcity,
Reciprocity, and Commitment and Consistency with our self-beliefs. We
consider ourselves to be good people, and our actions show others that
we are just as good as them, or better.</p>

The fourth idea is that <a
href="https://www.psychologytoday.com/us/blog/science-choice/201504/what
-is-confirmation-bias">we believe that things are true because we would
like them to be true.</a> When we look for evidence of something, we
tend to see what we want to see. And when we find evidence that confirms
our beliefs, we tend not to keep looking for evidence that contradicts
those beliefs or provides a different, but valuable, perspective.</p>


Learn more about our research at <a
href="index.html">socialcybersecurity.org</a> and by
looking up the references listed here. </span>





    	</section>

    <!-- Sidebar --> <aside class="sidebar"> <h2>References</h2> <ul>
    <li>Robert B. Cialdini. 1987. Influence. A. Michel Port Harcourt.
    </li>

<li>Robert B. Cialdini and Noah J. Goldstein. 2004. Social influence:
compliance and conformity. Annual review of psychology 55: 591–621.</li>

<li>D. T. Gilbert, D. S. Krull, and P. S. Malone. 1990. Unbelieving the
unbelievable: Some problems in the rejection of false information.
Journal of personality and social psychology. Retrieved from
http://doi.apa.org/journals/psp/59/4/601.html </li>

<li>Noah J. Goldstein, Robert B. Cialdini, and Vladas Griskevicius. 2008. A room with a viewpoint: Using social norms to motivate environmental conservation in hotels. The Journal of consumer research 35, 3: 472–482.
 </li>

<li>Daniel Kahneman. 2011. Thinking, Fast and Slow. Macmillan.</li>

<li>Daniel Kahneman and Amos Tversky. 2000. Choices, Values, and Frames.
Cambridge University Press.</li>

<li>Raymond S. Nickerson. 1998. Confirmation bias: A ubiquitous
phenomenon in many guises. Review of general psychology: journal of
Division 1, of the American Psychological Association 2, 2: 175.</li>

    </ul> </aside>

</div>

    <!-- Footer --> <footer>


    <p>Copyright 2019-2020. We are funded by
    the U.S. National Science Foundation under <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1704087">grant no. CNS-1704087.</a> </p> <p>This site was built
    with the Simple Responsive Layout template from
    <a href="https://github.com/thecodercoder/Simple-Responsive-Layout">https://github.com/thecodercoder/Simple-Responsive-Layout</a></p>

    <div> <img src='images/HCII_NSF_logo.png' style='max-height:50px;
    float: left; margin: 0px 0px 0px 0px'/> <img
    src='images/CyLab_Chimps_logo.png' style='max-height:50px; float:
    left; margin: 0px 0px 0px 0px'/> <img src='images/CoExLab_logo.png'
    style='max-height:50px; float: left; margin: 0px 0px 0px 0px'/>
    </div> </footer>

</main> </body> </html>
